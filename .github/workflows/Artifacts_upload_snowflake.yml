name: Upload dbt Artifacts to Snowflake

on:
  workflow_run:
    workflows:
      - dbt  # Replace with the name of your dbt run workflow
    types:
      - completed

jobs:
  upload_artifacts:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }} # Only upload if dbt run was successful

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'  # Or a suitable version

      - name: Install Snowflake Connector
        run: |
          pip install snowflake-connector-python

      - name: Upload dbt Artifacts to Snowflake
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
          
        run: |
          import snowflake.connector
          import json
          import os
          from pathlib import Path

          # Snowflake connection details from environment variables
          sf_account = os.environ['SNOWFLAKE_ACCOUNT']
          sf_user = os.environ['SNOWFLAKE_USER']
          sf_password = os.environ['SNOWFLAKE_PASSWORD']
          sf_database = os.environ['SNOWFLAKE_DATABASE']
          sf_schema = os.environ['SNOWFLAKE_SCHEMA']

          # Path to the dbt target directory
          dbt_target_dir = 'target'  # Default dbt target directory in your repo

          # Function to upload JSON data to Snowflake
          def upload_json_to_snowflake(conn, schema, table_name, json_data):
              try:
                  cursor = conn.cursor()
                  # Create table if it doesn't exist
                  create_table_sql = f"""
                  CREATE TABLE IF NOT EXISTS {schema}.{table_name} (
                      data VARIANT
                  )
                  """
                  cursor.execute(create_table_sql)

                  # Insert the JSON data
                  insert_sql = f"INSERT INTO {schema}.{table_name} (data) VALUES (%s)"
                  cursor.execute(insert_sql, (json.dumps(json_data),))
                  conn.commit()
                  print(f"Uploaded data to {schema}.{table_name}")
              except Exception as e:
                  print(f"Error uploading to {table_name}: {e}")
                  conn.rollback()
              finally:
                  cursor.close()

          # Connect to Snowflake
          try:
              conn = snowflake.connector.connect(
                  account=sf_account,
                  user=sf_user,
                  password=sf_password,
                  database=sf_database,
                  schema=sf_schema
              )
              print("Connected to Snowflake")

              # Upload artifacts
              for file_path in Path(dbt_target_dir).glob("*.json"): #changed from .rglob to .glob
                  if file_path.is_file():
                      try:
                          with open(file_path, 'r') as f:
                              json_data = json.load(f)
                              table_name = file_path.stem  # Use filename without extension as table name
                              upload_json_to_snowflake(conn, sf_schema, table_name, json_data)
                      except Exception as e:
                          print(f"Error processing file {file_path}: {e}")

          except Exception as e:
              print(f"Error connecting to Snowflake: {e}")
          finally:
              if 'conn' in locals():
                conn.close()

